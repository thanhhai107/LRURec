from .base import AbstractDataset
from .utils import *

from datetime import datetime, timezone
from pathlib import Path
import pickle
import shutil
import tempfile
import os
import json
import pandas as pd
from tqdm import tqdm
tqdm.pandas()


class Yelp2020Dataset(AbstractDataset):
    @classmethod
    def code(cls):
        return 'yelp2020'

    @classmethod
    def url(cls):
        return 'https://drive.google.com/uc?id=1ugbgehShD2xTqdFWcNoba6xN5IQnT93R'

    @classmethod
    def zip_file_content_is_folder(cls):
        return True

    @classmethod
    def all_raw_file_names(cls):
        return ['yelp_academic_dataset_review.json']

    def maybe_download_raw_dataset(self):
        folder_path = self._get_rawdata_folder_path()
        if folder_path.is_dir() and all(folder_path.joinpath(f).is_file() for f in self.all_raw_file_names()):
            print('Raw data already exists. Skip downloading')
            return
        
        print("Downloading Yelp2020 dataset from Google Drive...")
        import gdown
        
        tmproot = Path(tempfile.mkdtemp())
        tmpzip = tmproot.joinpath('file.zip')
        tmpfolder = tmproot.joinpath('folder')
        
        gdown.download(self.url(), str(tmpzip), quiet=False)
        unzip(tmpzip, tmpfolder)
        
        # Check if unzipped content is in a subfolder
        subfolders = list(tmpfolder.iterdir())
        if len(subfolders) == 1 and subfolders[0].is_dir():
            actual_folder = subfolders[0]
        else:
            actual_folder = tmpfolder
        
        # Create parent directory if it doesn't exist
        folder_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Move to final location
        if folder_path.exists():
            shutil.rmtree(folder_path)
        shutil.move(str(actual_folder), str(folder_path))
        shutil.rmtree(tmproot)
        print()

    def preprocess(self):
        dataset_path = self._get_preprocessed_dataset_path()
        if dataset_path.is_file():
            print('Already preprocessed. Skip preprocessing')
            return
        if not dataset_path.parent.is_dir():
            dataset_path.parent.mkdir(parents=True)
        self.maybe_download_raw_dataset()
        df = self.load_ratings_df()
        # Filter for year 2019 using UTC timezone to match the source data
        df = df[(df['timestamp'] >= pd.Timestamp('2019-01-01', tz='UTC').timestamp()) & 
                (df['timestamp'] < pd.Timestamp('2020-01-01', tz='UTC').timestamp())]
        print(f'After filtering 2019: {len(df):,} reviews, {df["uid"].nunique():,} users, {df["sid"].nunique():,} items')
        df = self.filter_triplets(df)
        print(f'After 5-core filtering: {len(df):,} reviews, {df["uid"].nunique():,} users, {df["sid"].nunique():,} items')
        df, umap, smap = self.densify_index(df)
        train, val, test = self.split_df(df, len(umap))
        
        dataset = {'train': train, 'val': val, 'test': test, 'umap': umap, 'smap': smap}
        with dataset_path.open('wb') as f:
            pickle.dump(dataset, f)

    def load_ratings_df(self):
        folder_path = self._get_rawdata_folder_path()
        file_path = folder_path.joinpath(self.all_raw_file_names()[0])
        
        print('Loading Yelp2020 reviews...')
        data = []
        
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in tqdm(f, desc='Reading reviews'):
                review = json.loads(line)
                # Date in source file is UTC+0, so we need to specify timezone explicitly
                timestamp = datetime.strptime(review['date'], '%Y-%m-%d %H:%M:%S').replace(tzinfo=timezone.utc).timestamp()
                
                data.append({
                    'uid': review['user_id'],
                    'sid': review['business_id'],
                    'rating': review['stars'],
                    'timestamp': timestamp
                })
        
        df = pd.DataFrame(data)

        print('Sorting reviews by timestamp...')
        df = df.sort_values('timestamp').reset_index(drop=True)
        
        print(f'Total reviews loaded: {len(df):,}')
        return df
